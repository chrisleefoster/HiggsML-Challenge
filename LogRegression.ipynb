{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA #\n",
    "import numpy as np\n",
    "\n",
    "# features consists of the EventID and the 30 features\n",
    "features = np.loadtxt(\"atlas-higgs-challenge-2014-v2.csv\", delimiter=\",\", skiprows=1, usecols=range(0,31))\n",
    "\n",
    "# labels consists of the EventID, a weight, and a label\n",
    "# the weights are used for the unnormalized true positives and false positive rates in the AMS calculation\n",
    "labels = np.loadtxt(\"atlas-higgs-challenge-2014-v2.csv\", delimiter=\",\", skiprows=1, usecols=(0,31,32), dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out what the data looks like\n",
    "print(features[0])\n",
    "print(labels[0])\n",
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize feature values\n",
    "# scale all but first column (EventID)\n",
    "scaler = StandardScaler().fit(features[:,1:])\n",
    "temp_features = scaler.transform(features[:,1:])\n",
    "\n",
    "# link EventIDs with scaled features\n",
    "scaled_features = features\n",
    "for sample in range(scaled_features.shape[0]):\n",
    "    scaled_features[sample, 1:] = temp_features[sample]\n",
    "\n",
    "# check out how it looks now\n",
    "print(scaled_features[1])\n",
    "print(scaled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split to test and train sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(scaled_features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the split data\n",
    "print(features_train[0])\n",
    "print(labels_train[0])\n",
    "print(features_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create solution submission for AMS metric\n",
    "import csv\n",
    "\n",
    "# the provided AMS calculation requires a csv file with each sample's: EventID, Class, Weight\n",
    "with open('solution.csv', 'w', newline='') as solution_file:\n",
    "    headings = ['EventId', 'Class', 'Weight']\n",
    "    writer = csv.DictWriter(solution_file, fieldnames=headings)\n",
    "    writer.writeheader()\n",
    "    for sample in range(labels_test.shape[0]):\n",
    "        writer.writerow({\"EventId\": labels_test[sample,0], \"Class\": labels_test[sample,2], \"Weight\": labels_test[sample,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels from string to binary\n",
    "for label in range(labels_train.shape[0]):\n",
    "    if labels_train[label,-1] == 'b':\n",
    "        labels_train[label,-1] = 0\n",
    "    else:\n",
    "        labels_train[label,-1] = 1\n",
    "\n",
    "for label in range(labels_test.shape[0]):\n",
    "    if labels_test[label,-1] == 'b':\n",
    "        labels_test[label,-1] = 0\n",
    "    else:\n",
    "        labels_test[label,-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data again\n",
    "print(labels_test[0])\n",
    "print(labels_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='newton-cholesky')\n",
    "model.fit(features_train[:,1:], labels_train[:,-1])\n",
    "predictions = model.predict(features_test[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels back to char, 's' or 'b'\n",
    "labels_pred = [0] * predictions.shape[0]\n",
    "for label in range(predictions.shape[0]):\n",
    "    if predictions[label] == '0':\n",
    "        labels_pred[label] = 'b'\n",
    "    else:\n",
    "        labels_pred[label] = 's'\n",
    "print(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction submission for AMS metric calculation\n",
    "with open('submission.csv', 'w', newline='') as submission_file:\n",
    "    headings = ['EventId', 'RankOrder', 'Class']\n",
    "    writer = csv.DictWriter(submission_file, fieldnames=headings)\n",
    "    writer.writeheader()\n",
    "    for sample in range(labels_test.shape[0]):\n",
    "        writer.writerow({\"EventId\": labels_test[sample,0], \"RankOrder\": sample, \"Class\": labels_pred[sample]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AMS\n",
    "import HiggsBosonCompetition_AMSMetric_rev1 as ams\n",
    "ams.AMS_metric(\"solution.csv\", \"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
